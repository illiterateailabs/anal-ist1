# MCP_IMPLEMENTATION_PLAN.md  
*Integrating Model Context Protocol into analystt1*  
**Version:** 0.1 · **Draft Date:** 02 Jun 2025 · **Owner:** Marian Stanescu  

---

## 1. Executive Summary  
Model Context Protocol (MCP) is an open standard that lets LLMs access external tools, data and prompts through a unified client/server interface (JSON-RPC 2.0 over stdio or SSE HTTP).  
Adopting MCP for analystt1 will:  

* Standardise how CrewAI agents call ~30 custom tools (Neo4j queries, e2b sandboxes, GNN inference, crypto APIs).  
* Leverage Gemini 2.5 Pro/Flash **native MCP support** → no custom function-calling glue.  
* Reduce coupling between agents and tool code, enabling hot-plugging new fraud-detection micro-tools.  
* Improve security (schema-validated inputs), observability (standard events), and multi-model portability (Claude, Mistral, GPT soon support MCP).  

---

## 2. Current-State Analysis  

| Layer | Implementation | Pain-points for Integration |
|-------|----------------|-----------------------------|
| **Agents** | CrewAI agents orchestrated via `CrewFactory` | Direct `BaseTool` classes tightly coupled, manual arg validation. |
| **Tools** | ~25 Python tools (Neo4j, e2b, Gemini, CSV loader, GNN, etc.) | Heterogeneous signatures, inconsistent schemas, process lifecycle hidden in FastAPI workers. |
| **LLM** | Google Gemini API (2.5 Pro/Flash) via `GeminiClient` wrapper | Uses custom tool-calling JSON => lose type info; no standard discovery. |
| **Infra** | FastAPI backend, Neo4j 5.15, Redis, Docker, GitHub CI | Tool code bundled in backend image → heavy. |
| **Security** | RBAC, JWT, e2b sandbox | Tool-argument sanitisation ad-hoc. |

---

## 3. Target MCP Architecture  

```
CrewAI Agent  ─┐               ┌─►  MCP-Server (GraphQuery)
               │   JSON-RPC    │
CrewAI MCP-Client (crewai-mcp-toolbox)
               │               ├─►  MCP-Server (GNN Predict)
Gemini 2.5 ◄───┘               └─►  MCP-Server (e2b Sandbox)
```

### Components  
1. **MCP Client Gateway**  
   *Use package `crewai-mcp-toolbox`*; auto-generates CrewAI tools from server schemas.  
2. **MCP Servers (Python)**  
   | Server | Tools exposed | Owner pkg |
   |--------|---------------|-----------|
   | `mcp-graph` | `cypher_query`, `subgraph_extract` | neo4j-client |
   | `mcp-gnn`   | `gnn_predict`, `gnn_train`, `experiment_stats` | gnn_training_tool |
   | `mcp-sandbox` | `python_exec`, `npm_exec` | e2b-client |
   | `mcp-crypto` | `fetch_tx`, `price_series`, `detect_anomaly` | crypto tools |

3. **Transport**  
   *Local*: stdio subprocess for low-latency tool calls.  
   *Remote*: SSE HTTP behind FastAPI `/mcp/*` proxy for distributed scaling.

4. **Registry & Discovery**  
   Simple YAML registry (`config/mcp_servers.yaml`) lists server launch cmds, env, security policy. CrewFactory reads registry on boot.

---

## 4. Phase-by-Phase Roadmap  

| Phase | Scope | Milestones | ETA |
|------|-------|------------|-----|
| **P0 – Enable MCP Client (1 wk)** | • Add `crewai-mcp-toolbox` dep<br>• Prototype connecting Gemini 2.5 to sample `server-filesystem` | Demo conversation tool list & call; CI smoke test | **Wk 23** |
| **P1 – Wrap Key Tools (2 wks)** | Wrap GraphQueryTool, GNNFraudDetectionTool, SandboxExecTool as MCP servers using `mcpengine` | Servers start via Make targets; schemas auto-generated; E2E tests green | Wk 25 |
| **P2 – CrewAI Refactor (1 wk)** | Replace legacy `BaseTool` refs with MCP-generated tools in 3 primary crews (`fraud_pattern_hunter`, `graph_analyst`, `gnn_analyst`) | Coverage ≥55 %, perf parity | Wk 26 |
| **P3 – Prod Hardening (2 wks)** | • SSE HTTP transport behind FastAPI<br>• Auth-token passthrough to servers<br>• Prometheus metrics via MCP events<br>• Blue/green deployment scripts | Load-test ≥500 concurrent calls; security pen-test passed | Wk 28 |

---

## 5. Technical Specifications & Requirements  

| Item | Spec |
|------|------|
| **Protocol** | JSON-RPC 2.0 messages, v0.5 MCP schema |
| **Transport** | stdio (dev/local), HTTP + SSE (prod) |
| **Schemas** | Draft-07 JSON-Schema per tool → autogenerated Pydantic for Python |
| **Auth** | JWT Bearer forwarded via `Authorization` header to HTTP servers; RBAC guard at gateway |
| **Observability** | Standard `listChanged`, `toolCalled`, `toolCompleted` events collected by backend logger & Prometheus exporter |
| **CI** | Add MCP integration job → spin stdio servers, run `pytest tests/test_mcp_*` |
| **Images** | New `docker-compose.mcp.yml` includes side-car containers for each server |
| **Dependencies** | `mcpengine>=0.3`, `crewai-mcp-toolbox>=0.2`, update constraints.txt |

---

## 6. Gemini API Integration  

* Gemini 2.5 already supports `tools` arrays with MCP.  
* Update `GeminiClient.generate_content()` to set `tools={"mcp":True}` when session has active MCP client.  
* Remove bespoke function-calling shim → less prompt bloat, faster tokens.  
* For Flash model, gateway auto-downgrades to legacy tools if `mcp` unsupported.

---

## 7. Migration Strategy  

1. **Dual-Path Period (P1)** – Keep current `BaseTool` classes; introduce parallel MCP servers; A/B test crews.  
2. **Traffic Shifting (P2)** – Feature flag `USE_MCP=true` -> route 100 % of traffic through MCP tools.  
3. **Deprecation (P3)** – Remove legacy tool code, shrink backend image; doc update.  

Data compatibility: ensure output schema identical; write thin adapters where necessary.

---

## 8. Expected Outcomes  

| Dimension | Impact |
|-----------|--------|
| Dev velocity | +30 % faster tool onboarding (schema-first) |
| Reliability | Standard error envelopes, restartable servers |
| Security | Schema validation, isolated processes |
| Scalability | Horizontal scale each MCP server independently |
| Model portability | Easy switch to Claude/Mistral for comparison |
| Operating cost | Smaller agent prompts → ‑15 % tokens with Gemini |

---

## 9. Risk Assessment  

| Risk | Likelihood | Mitigation |
|------|------------|------------|
| **Protocol churn** (MCP <1.0) | Med | Pin SDK versions; follow spec updates; wrappers behind facade |
| **Latency increase** via stdio | Low | Keep heavy compute (GNN) local; benchmark; enable batch calls |
| **Team learning curve** | Med | Internal workshop; code templates |
| **Docker image size** | Low | Split servers into slim images |
| **Security of new endpoints** | Med | RBAC middleware, allowlist tool schemas, rate-limit |

---

## 10. Timeline & Resources  

| Resource | Allocation |
|----------|------------|
| **Lead Engineer** | 30 h / wk (design, refactor) |
| Backend dev ×2 | 20 h / wk (server wrappers, testing) |
| DevOps | 10 h / wk (CI jobs, Docker, k8s sidecars) |
| QA / Security | 8 h / wk (pen-test, benchmarks) |

**Total Effort:** ~160 h over **4 weeks** (Wk 23-28).  
Budget adjustment: +$1.2k for PyTorch-compatible MCP runners in CI.

---

### Approval  
Sign-off required from: CTO, Head of AI, Security Lead, DevOps Lead.  

*Prepared by Factory Droid · 02 Jun 2025*  
